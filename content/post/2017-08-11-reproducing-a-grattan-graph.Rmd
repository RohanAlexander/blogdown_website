---
title: Reproducing a Grattan Institute graph
author: Rohan
date: '2017-08-11'
slug: reproducing-a-grattan-graph
categories: []
tags: []
draft: no
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(knitr)
```

*tl;dr: I was pretty much able to reproduce a recent interactive map from the Grattan Institute. I found that the released dataset doesn't correspond with the published map for the one that I reproduced. But following their notes I was able to get values that were the same to those illustrated in the map for many areas. It is great that the Grattan Institute is making an effort to be more open with its data, but it should also make its code available. Moving from Carto to ggmap/leaflet for mapping could also help by better integrating the data analysis process with the reporting.*

*(Disclosures: In the interest of transparency I'll point out that I applied unsuccessfully for a job at the Grattan Institute about five years ago. One friend works as a research assistant for them on a casual basis; and there are a few friends-of-friends who work there full time, but I haven't talked about any of this with any of them.)*

# Introduction
The Grattan Institute is an Australian think-tank that produces reports about public policy. One released last week - [Regional patterns of Australia's economy and population](https://grattan.edu.au/report/regional-patterns-of-australias-economy-and-population/) - looked into the differences between geographic areas across various economic and demographic variables. Earlier this year I spent a fair bit of time getting comfortable making static and interactive maps. So I was curious to see if I could independently reproduce one of the interactive maps - [Annual income growth per person (FY04 - FY15)](https://grattan.carto.com/me) - in an hour.

I was reasonably successful in using R's Leaflet package and the dataset that the Grattan Institute said underpinned the maps to visually reproduce what they'd done in Carto in just an hour. But it didn't stand up to closer inspection. It took the rest of the day for me to conclude that the data that the Grattan Institute mapped is reasonable but for this map the dataset they released is wrong.

The final map that I produced is available below and the note that follows documents what I did to produce it.

**INSERT LINK TO THE MAP HERE**




# Workspace
The first step is to set-up the workspace. Mostly this just means loading packages. The <tt>tidyverse</tt> and <tt>magrittr</tt> packages help with general data manipulation tasks; <tt>zoo</tt> helps with the rolling average; and <tt>leaflet</tt>, <tt>rgdal</tt>, and <tt>rmapshaper</tt> are specific to mapping.

```{r, eval=FALSE}
library(tidyverse)
library(magrittr)
library(zoo)
library(leaflet)
library(rgdal)
library(rmapshaper)
#update.packages()
# Change working directory
setwd("~/Documents/projects/coriander")
```


# Data
I decided to reproduce Figure 2.4 of the report. This shows the average annual growth in real taxable income per tax filer between the financial years 2003/04 and 2014/15 for the 2011 SA3 areas. To do this I needed the incomes data that the Grattan Institute mapped and the geographic data that defines the areas.

## Incomes
The Grattan Institute released the datasets that they said underlie the charts. It was straightforward to download this and export the relevant sheet as a csv file. The excel file is available at https://grattan.edu.au/report/regional-patterns-of-australias-economy-and-population/ (in the left panel).

```{r, eval=FALSE}
#### Data ####
# Import the income data that has been taken from the Grattan data download, sheet 'Figure 2.4'. I saved that particular sheet as a CSV.
incomes <- read_csv("data/890-Regional-patterns-chart-data.csv")
names(incomes)
# Remove some columns of debris that aren't important
incomes <- incomes %>%
  select("SA3", "Growth_mean_income_FY04_FY15")
```

## Geographies
The other dataset that I needed was the geographies that the Grattan Institute had used. I initially wasted a lot of time using the 2016 SA3 release. After a lot of messing around I realised they were using the SA3 release from 2011. This is available from the ABS website at: http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.001July%202011?OpenDocument and I used the zipped file: 'Statistical Area Level 3 (SA3) ASGS Ed 2011 Digital Boundaries in ESRI Shapefile Format'.

```{r, eval=FALSE}
#### Read in the shapefiles (maps) that show each of the boundaries of the SA3-level area.

# 2016 SA3 boundaries
boundaries <- readOGR(dsn = "data/1270055001_sa3_2016_aust_shape", layer = "SA3_2016_AUST")
# Add the incomes dataset into the boundaries dataset
boundaries <- merge(boundaries, incomes, by.x = "SA3_NAME16", by.y = "SA3")

# 2011 SA3 boundaries
old_boundaries <- readOGR(dsn = "data/1270055001_sa3_2011_aust_shape", layer = "SA3_2011_AUST")
# Again, push the income data into the boundaries dataset
old_boundaries <- merge(old_boundaries, incomes, by.x = "SA3_NAME11", by.y = "SA3")
```

Comparing the incomes data with the 2011 geographies data you notice that the incomes data is missing two SA3 areas: 'Illawarra Catchment Reserve' and 'Blue Mountains - South'. If you look at Grattan's interactive map for long enough you'll notice they too have NAs in those two areas. While this gives some reassurance that the 2011 geographies are the right ones to be using, it was a bit annoying that this wasn't documented somewhere (although it's possible I missed it).

# Breaks and colours
Reproducing the breaks that Grattan used was straightforward by copying their bins. Box 1 in Appendix A of the Grattan Institute's report specifies how they came up with these bins. Give my purposes I didn't worry too much about this.

I also didn't spend too much time on the colours because the inferno palette got fairly close.

```{r, eval=FALSE}
#### Specify the colour schemes that will be used. ####
# Set the color scheme for the booth coloring (virdis options are: "viridis", "magma", "plasma" and "inferno", but there are lots)
pal <- colorBin(
  palette = "inferno",
  domain = old_boundaries$Growth_mean_income_FY04_FY15,
  bins = c(0, 0.005, 0.012, 0.015, 0.017, 0.019, 0.022, 0.029, 0.07),
  reverse = TRUE
  )
```


# Map
Once the pieces were in place it was straightforward to make a map. I called leaflet and specified a black and white base map that is similar to the Grattan Institute's. After that I adjusted the default view and then added the patchwork quilt that shows the incomes dataset by SA3 area.

```{r, eval=FALSE}
#### Pull it all together to make the map ####
# Make the map
Australia_incomes_map <- 
  leaflet() %>%
  # Base groups
  addProviderTiles(providers$Stamen.TonerLite, group = "Toner Lite") %>% # Add a black and white alternative
  setView(lng = 133.7751, lat = -25.2744, zoom = 4) %>% # Specify where the map is initially focused
  addPolygons(data = old_boundaries, 
              color = pal(old_boundaries$Growth_mean_income_FY04_FY15), 
              weight = 1, 
              stroke = FALSE,
              smoothFactor = 0.5,
              fillOpacity = 0.8, 
              label = paste("Area name (SA3):", as.character(old_boundaries$SA3_NAME11), 
                            "Mean annual growth:", as.character(old_boundaries$Growth_mean_income_FY04_FY15)),
              highlightOptions = highlightOptions(color = "#666", weight = 2, bringToFront = FALSE)) %>% 
  addLegend("bottomright", pal = pal, values = old_boundaries$Growth_mean_income_FY04_FY15,
            title = "Mean annual income growth (FY04 - FY15)",
            #labFormat = labelFormat(prefix = "$"),
            opacity = 0.4
  )

# Call the map
Australia_incomes_map
```

There were many small tweaks that could be made to this default map to better reproduce the Grattan map, but at this stage I realised there was something going on with the data. I decided to spend more time with that than tweaking the remaining aspects.

# Comparison 
## Issues
Comparing screenshots of the maps it was clear that there were substantial data issues.

![Grattan's map](/img/grattan.png)

![My map](/img/me.png)

There are areas where my map has a lot more variation such as:

* the northern SA3 areas of Queensland; and
* the SA3 areas in the south west of Western Australia.

There are also some areas where the colours are fairly different (notwithstanding the fact that I didn't match theirs exactly they should be similar), such as:

* west of Melbourne where my values are a lot higher.

## Triage
I checked that I was using the dataset that I had meant to use. While I was checking this dataset (which is the one that the Grattan Institute makes available) I noticed that the numbers in the Grattan Institute's dataset were not always the ones that were being mapped. This was easy to see because they included a static version of the map next to the dataset, so I was confident it was meant to be the same. 

Annoyingly, I couldn't work out how to download the actual dataset underlying the interactive Carto map, but I was able to check some on an area-by-area basis because the value was display on hover. I found that the figure that was displayed did line up with the colour of the area, but not the dataset that they offered as underlying the map.

The following table summarises some of the other SA3 areas. Note that I haven't converted the dataset values into percentages but other than a magnitude it shouldn't affect anything.

SA3 Area  | Grattan Carto value | Grattan data value
------------- | ------------- | -------------
Far North   | 2.66 | 0.030
Outback - North  | 2.33 | 0.017
Port Douglas - Daintree  | 1.73 | 0.014
Tablelands (East) - Kuranda  | 2.23 | 0.016
Cairns - South  | 1.73 | 0.020
Charters Towers - Ayr - Ingham  | 2.35 | 0.016

The key issue is which is right - the Carto map which is the one in the report or the dataset that they released. If the report is correct then this isn't a big deal because I'd be surprised if many people looked at the accompanying dataset!

## Investigation
By this stage it was after dinner, and I'll admit that I was a glass or three of wine down. But the only way to work out whether it was the dataset or the map that was wrong was to recreate the series myself. To do this I needed: 

* incomes data for the financial years 2003-04 and 2014-15;
* an inflation rate over this time to make the 2003-04 data real;
* a correspondence from postcodes (which is the geography that the incomes data is available on) to the 2011 SA3 areas.

Without their code it's hard to be sure, but luckily the Grattan Institute provided enough information so that I was able to get reasonably close to their results.

### Incomes
The incomes data is from Table 8 of the 2015 tax stats which is available here:
https://data.gov.au/dataset/taxation-statistics-2014-15/resource/02e58971-ddee-4f77-af15-5c45de569ed6

```{r, eval=FALSE}
# Import the tax data
tax_data <- read_csv("data/taxstats2015individual08medianaveragetaxableincomestateterritorypostcode.csv", skip = 2, col_names = FALSE)
# Remove the debris rows
tax_data <- tax_data[2:2254,]
# Grattan says we only need postcode, the 2003/04 data and the 2014/15 data, so drop the rest of the variables
tax_data <- tax_data %>%
  select(X2:X5, X11:X13)
# Fix the column names
tax_data <- rename(tax_data, "postcode" = X2, "population_0304" = X3, "median_inc_0304" = X4, "ave_inc_0304" = X5, "population_1415" = X11, "median_inc_1415" = X12, "ave_inc_1415" = X13)
# Finally, change the classes to numeric (need to remove the comma first)
tax_data$population_0304 <- sub(",", "", tax_data$population_0304)
tax_data$median_inc_0304 <- sub(",", "", tax_data$median_inc_0304)
tax_data$ave_inc_0304 <- sub(",", "", tax_data$ave_inc_0304)
tax_data$population_1415 <- sub(",", "", tax_data$population_1415)
tax_data$median_inc_1415 <- sub(",", "", tax_data$median_inc_1415)
tax_data$ave_inc_1415 <- sub(",", "", tax_data$ave_inc_1415)
tax_data$postcode <- as.numeric(tax_data$postcode)
tax_data$population_0304 <- as.numeric(tax_data$population_0304)
tax_data$median_inc_0304 <- as.numeric(tax_data$median_inc_0304)
tax_data$ave_inc_0304 <- as.numeric(tax_data$ave_inc_0304)
tax_data$population_1415 <- as.numeric(tax_data$population_1415)
tax_data$median_inc_1415 <- as.numeric(tax_data$median_inc_1415)
tax_data$ave_inc_1415 <- as.numeric(tax_data$ave_inc_1415)
```

### Inflation
I needed to change the financial year 2003-04 into 2014-15 dollars. In the Grattan Institute's report (p. 34) they say:

> Nominal income for the 2003-04 financial year was adjusted to real
2014-15 dollars, using a yearly average of ABS quarterly data on the
Consumer Price Index, starting from the 2003 September quarter.

I downloaded the inflation data that they specified from:
http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/6401.0Mar%202017?OpenDocument
(it is Tables 1 and 2 of the release). It is series A2325846C. I wasn't entirely sure of how the Grattan Institute was constructing its measure, but decided to just go with the RBA formula (http://www.rba.gov.au/calculator/) which is (Average of the four quarters in the final year / average of the four quarters in the first year - 1) *100 (although I didn't need to worry about removing one or the multiplying. 

```{r, eval=FALSE}
# Import the inflation data
inflation_data <- read_csv("data/640101.csv", skip = 10, col_names = FALSE)
# Grab the series they use: A2325846C
inflation_data <- inflation_data %>%
  select(X1, X10)
# Fix the column names
inflation_data <- rename(inflation_data, 
                   "quarter" = X1,
                   "index_value" = X10
)
# To use the RBA formula we need the average index number over the four quarters
inflation_data <- inflation_data %>%
  mutate(
    average_index_over_year = rollmean(index_value, 4, align = 'right', fill = NA)
  )
# Now we just use (final_year_ave / first_year_ave) (don't need to bother with removing the 1 or multiplying by 100 because we are just going to multiply the first years data up to get in terms of final year)
inflation_rate <- 
  ((inflation_data$average_index_over_year[inflation_data$quarter == "Jun-2015"] / inflation_data$average_index_over_year[inflation_data$quarter == "Jun-2004"]))
```

This ends up with an adjustment of about 1.34. I also worked out the annual inflation rates and then chained them, and also just using the start and end quarter index numbers (not averaged). They came to fairly similar values, so even though I'm not exactly sure what the Grattan Institute has done here, it shoudn't matter too much.

### Growth
Now I created the series that the Grattan Institute (p. 34) is interested in: 

> Growth in taxable income is calculated as a compound annual growth
rate from the 2003-04 financial year to the 2014-15 financial year.

```{r, eval=FALSE}
## Data manipulation - create the new interest variable that is of interest - 11 years?
tax_data <- tax_data %>%
  mutate(
    real_ave_inc_0304 = ave_inc_0304 * inflation_rate,
    real_median_inc_0304 = median_inc_0304 * inflation_rate,
    annual_ave_growth = (ave_inc_1415/real_ave_inc_0304)^(1/11),
    annual_median_growth = (median_inc_1415/real_median_inc_0304)^(1/11)
  )
```


### Correspondence
The incomes data that the ATO makes available is on a postcode basis. I needed to convert this into 2011 SA3 levels. Luckily the ABS makes a correspondence available from: 
http://www.abs.gov.au/AUSSTATS/abs@.nsf/DetailsPage/1270.0.55.006July%202011?OpenDocument where the right table is the zipped file 'Postcode 2011 to Statistical Area Level 3 2011'.

```{r, eval=FALSE}
# Import the correspondence
correspondence <- read_csv("data/1270055006_CG_POSTCODE_2011_SA3_2011.csv", skip = 7, col_names = FALSE)
correspondence <- correspondence %>%
  select(X2:X6)
# Fix the column names
correspondence <- rename(correspondence, 
                   "postcode" = X2,
                   "SA3_CODE_2011" = X3,
                   "SA3_NAME_2011" = X4,
                   "ratio" = X5,
                   "percentage" = X6
)

correspondence <- merge(correspondence, tax_data, by.x = "postcode", by.y = "postcode")
match

correspondence <- correspondence %>%
  mutate(
    contribution_ave = ratio * annual_ave_growth,
    contribution_median = ratio * annual_median_growth
  )

sa3_data <- correspondence %>%
  group_by(SA3_NAME_2011) %>%
  summarise(
    ave_growth = weighted.mean(annual_ave_growth, ratio, na.rm = T),
    median_growth = weighted.mean(annual_median_growth, ratio, na.rm = T)
  )
```

This result of all this is that I created a dataset that should be fairly similar to the one that the Grattan Institute created.
```{r, eval=TRUE}
load("sa3_data.Rda")
head(sa3_data)
```

Comparing the areas that were in the earlier table, my estimates consistently seemed a little lower than their estimates. The immediate reason for the difference that came to mind is that I may have a slightly different inflation rate or may have made a mistake in the correspondence.

SA3 Area  | Grattan Carto value | Grattan data value | My value
------------- | ------------- | ------------- | -------------
Cairns - South  | 1.73 | 0.020 | 1.81
Charters Towers - Ayr - Ingham  | 2.35 | 0.016 | 2.35
Far North   | 2.66 | 0.030 | 2.66
Outback - North  | 2.33 | 0.017 | 2.33
Port Douglas - Daintree  | 1.73 | 0.014 | 1.73
Tablelands (East) - Kuranda  | 2.23 | 0.016 | 2.23



The good news for the Grattan Institute is that I think the maps in their report are broadly fine, and it was just the accompanying dataset that is wrong.

## Reconciliation
I've reached out to Grattan and will update this post based on what they say.

# Conclusion
The Grattan Institute is probably Australia's most important think tank in terms of not being overly associated with one side of politics but still making a contribution to thinking on policy. It is good that they are being more open about their datasets, but it would be much better if they made their code available. Using tools like leaflet and ggmap instead of Carto would help with this.

While it was fun to spend the day in the data-analyst's version of a treasure chase, hopefully the next time I decide to reproduce a Grattan Institute graph common sense prevails.

![I regret nothing :)](https://imgs.xkcd.com/comics/duty_calls.png)


